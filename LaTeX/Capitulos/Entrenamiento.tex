\chapter{Entrenamiento y resultados}
\label{cap:train}
\begin{resumen}
	Este capítulo describe el proceso de entrenamiento de los modelos, detalla la configuración utilizada y presenta las métricas cuantitativas que permiten comparar su desempeño. Posteriormente se discuten los resultados obtenidos.
\end{resumen}

\section{Modelos modificados entrenados}
Modificamos la capa de entrada del \emph{gold standard} para poder entrenar modelos con datos en matrices bidimensionales de cualquier tamaño, lo que nos permitió (con una modificación muy pequeña del \emph{gold standard}) entrenar modelos con imágenes como datos de entrenamiento.

Al transformar cada una de las doce derivaciones obtenemos una matriz (de dimensiones dependientes exclusivamente del tamaño de la señal de entrada y de los parámetros de la transformada). Esto significa que al aplicar la misma transformada a las doce derivaciones de un ECG, obtenemos doce matrices de las mismas dimensiones, pero el modelo necesita solamente una matriz. Para abordar este problema, concatenamos las matrices en el eje de su altura, lo que nos permite utilizar el modelo modificado con los datos de las transformadas.

En concreto, los modelos modificados que entrenamos son los siguientes:
\begin{itemize}
	\item \textbf{Modelo STFT}: Entrenado con los datos transformados utilizando los parámetros especificados en la subsección \ref{subsec:stft}
	\item \textbf{Modelo CWT Ricker}: Entrenado con los datos transformados utilizando los parámetros especificados en la subsección \ref{subsec:cwt} con el \emph{wavelet} de Ricker.
	\item \textbf{Modelo CWT Morlet}: Entrenado con los datos transformados utilizando los parámetros especificados en la subsección \ref{subsec:cwt} con el \emph{wavelet} de Morlet.
\end{itemize}

\section{Configuración del entrenamiento}
\subsection{\emph{Hardware} y \emph{software}}
Todos los entrenamientos se han realizado en \emph{bujaruelo}, una máquina del departamento de arquitectura de computadores y automática de la facultad de informática de la universidad.
\subsubsection{\emph{Hardware}}
\begin{itemize}
	\item \textbf{Procesador}: Intel(R) Xeon(R) CPU E5-2695 v3 @2.3GHz
	\item  \textbf{GPUs}: El equipo tiene en total cuatro gráficas, dos de cada uno de los modelos siguientes:
	\begin{itemize}
		\item NVIDIA GeForce GTX 1080
		\item NVIDIA GeForce GTX 980
	\end{itemize}
	\item \textbf{Discos}: El equipo cuenta con dos discos de 1TB, además del disco donde está montado el sistema operativo, de 74.5GB.
\end{itemize}
\subsubsection{\emph{Software}}
En el Anexo \ref{anexo:librerias} puede encontrarse una tabla con la totalidad de las librerías instaladas en el entorno de python que hemos utilizado (así como sus respectivas versiones), pero las más destacables para el trabajo son las siguientes:

\begin{itemize}
	\item \textbf{Python}: Utilizamos la versión 3.11.7
	\item \textbf{TensorFlow}: Utilizamos la versión 2.15, por motivos de compatibilidad con el modelo de Ribeiro.
	\item \textbf{CUDA y cuDNN}: Estas librerías son las que utiliza TensorFlow para realizar los entrenamientos en las gráficas de NVIDIA. En nuestro caso utilizamos las versiones 12.2 y 8.9 respectivamente.
\end{itemize}

Además, utilizamos \textbf{Matplotlib} 3.8.2 y \textbf{Seaborn} 0.13.2 para generar los gráficos y \textbf{Pandas} 2.2.0 y \textbf{Scikit-learn} 1.3.0 para procesar y analizar los datos y generar métricas.


\subsection{Parámetros de entrenamiento}
Para entrenar a los modelos se ha utilizado el script de entrenamiento que aparece en el repositorio del \emph{gold standard}, ligeramente modificado para que trabaje con los datos transformados, que tienen dimensiones diferentes a los datos originales.

\section{Resultados cuantitativos}
En la tabla \ref{tab:resultados_modelos} podemos ver los resultados de todos los entrenamientos.

\begin{table}[htbp]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l|l|ccccc|c|}
		\toprule
		\textbf{Modelo} & \textbf{Métrica} & \textbf{NORM} & \textbf{MI} & \textbf{STTC} & \textbf{CD} & \textbf{HYP} & \textbf{Global} \\
		\midrule
		% Modelo Original
		\multirow{4}{*}{\emph{Gold Standard}} 
		& F-1 Score         & 0.835 & 0.680 & 0.718 & 0.705 & 0.413 & 0.737 \\
		& Recall            & 0.849 & 0.603 & 0.665 & 0.647 & 0.284 & 0.687 \\
		& Precisión         & 0.822 & 0.778 & 0.780 & 0.773 & 0.759 & 0.796 \\
		& F Score ajustada  & --    & --    & --    & --    & --    & 0.628 \\
		\midrule
		% Modelo STFT
		\multirow{4}{*}{STFT} 
		& F-1 Score         & 0.826 & 0.536 & 0.687 & 0.672 & 0.466 & 0.706 \\
		& Recall            & 0.853 & 0.433 & 0.640 & 0.589 & 0.338 & 0.650 \\
		& Precisión         & 0.801 & 0.701 & 0.741 & 0.783 & 0.750 & 0.772 \\
		& F Score ajustada  & --    & --    & --    & --    & --    & 0.587 \\
		\midrule
		% Modelo CWT Morlet
		\multirow{4}{*}{CWT Morlet} 
		& F-1 Score         & 0.817 & 0.457 & 0.645 & 0.630 & 0.395 & 0.644 \\
		& Recall            & 0.857 & 0.342 & 0.636 & 0.548 & 0.270 & 0.623 \\
		& Precisión         & 0.780 & 0.688 & 0.654 & 0.741 & 0.732 & 0.734 \\
		& F Score ajustada  & --    & --    & --    & --    & --    & 0.540 \\
		\midrule
		% Modelo CWT Ricker
		\multirow{4}{*}{CWT Ricker} 
		& F-1 Score         & 0.775    & 0.316    & 0.629    & 0.587    & 0.426    & 0.628    \\
		& Recall            & 0.774    & 0.224    & 0.633    & 0.520    & 0.319    & 0.572    \\
		& Precisión         & 0.776    & 0.538    & 0.626    & 0.675    & 0.639    & 0.696    \\
		& F Score ajustada  & --    & --    & --   & --    & --    & 0.512    \\
		\bottomrule
	\end{tabular}
	}
	\caption{Resultados de los modelos (con tres dígitos decimales de precisión)}
	\label{tab:resultados_modelos}
\end{table}

\section{Análisis de los resultados}
Los datos de la sección anterior muestran que al entrenar el \emph{gold standard} con diversas transformadas arroja unos resultados destacablemente peores en casi todas las métricas. Esto puede deberse a:
\begin{itemize}
	\item Una curva de aprendizaje más compleja para los modelos que utilizan transformadas, ya que generalizar patrones en estas podría ser más complejo para la red neuronal que hacerlo sobre las señales sin transformar. Esta hipótesis además se apoya en el hecho de que los modelos transformados hayan necesitado varios días para entrenarse, a diferencia del \emph{gold standard} (que se pudo entrenar en tan solo unas horas).
	\item Una elección incorrecta de los parámetros para las transformadas, ya que, si bien estos se han elegido con el objetivo de cubrir los rangos de frecuencias donde aparecen las anomalías que estamos buscando, podrían elegirse una cantidad inmensa de configuraciones diferentes.
	\item Limitaciones de la arquitectura del \emph{gold standard}, ya que utiliza redes Conv1D, que se especializan en detectar patrones en series temporales en lugar de en imágenes.
	\item Al transformar el modelo en un clasificador binario, se ha utilizado un \emph{threshold} de 0.5 para decidir si el ECG entra dentro de cada una de las etiquetas. Es posible que utilizando diferentes valores se obtengan mejores predicciones.
\end{itemize}
