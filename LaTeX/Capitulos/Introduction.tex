\chapter*{Introduction}
\label{cap:introduction}
\addcontentsline{toc}{chapter}{Introduction}
\section{Motivation}
AI has transformed numerous fields. In particular, the medical field has experienced significant advances through the application of artificial intelligence to diagnostics and data analysis. One of the most promising areas is the automated interpretation of signals in an ECG, which is essential for the early detection of heart diseases. Cardiovascular diseases are one of the leading causes of death globally \citep{whocvd}, highlighting the need for fast and accurate diagnostic methods.

The analysis of ECG's has historically been performed by healthcare professionals, such as cardiologists, due to the complexity and variability of the signals. However, this process is slow, costly, and highly dependent on the specialist’s experience. By adopting \emph{Deep Learning} models, such as convolutional neural networks (CNN), the goal is to automate and enhance this analysis, providing rapid results that, in many cases, are comparable to those obtained by human experts \citep{hannun_cardiologist_2019}. This approach not only promises to increase diagnostic efficiency but also improve accuracy and reduce the workload of medical staff.

Nevertheless, for these tools to gain trust in clinical settings and meet quality and ethical standards, they must be explainable \citep{Molnar2019}. The explainability of AI models permits understanding and justifying the decisions made during the analysis of cardiac signals, a critical factor in high-impact applications such as medicine, where an error can directly affect patient health \citep{Goodman2017}.

Throughout this work, we will explore various neural network architectures and signal transformation techniques to classify and detect abnormalities in ECGs, aiming to develop and refine an ECG classifier model for four groups of cardiac anomalies. In addition, we will incorporate explainability methods so that model results can be interpreted and validated by healthcare professionals, which is essential for clinical adoption of these technologies.

\section{Objectives}
The main objective of this work is to modify, train, and evaluate the model originally proposed by \cite{ribeiro} (hereinafter, the “original model”) by applying it to the public PTB-XL database \citep{ptbxldb}. To achieve this, we will introduce a modification in the model’s input layer that allows the inclusion of transforms (e.g., STFT or CWT) to investigate whether converting the signal into different representations can improve performance. However, no changes are made to the model’s internal architecture.

Based on the above, the specific objectives are:

\begin{enumerate}
	\item \textbf{Train the original model} using the PTB-XL database.
	\item \textbf{Modify the original model} so that it accepts signal transformations, permitting the training of alternative versions of the model with transformed data.
	\item \textbf{Compare the performance} of each variant with the original model using metrics such as F1-Score, analyzing whether the transformations are beneficial.
	\item \textbf{Apply an explainability method} so that a specialist can understand which parts of the ECG signal influence the prediction. For reasons to be discussed later, this will only be applied to the original model.
\end{enumerate}

\section{Document structure}
This document is organized into six chapters, whose contents are described below:
\begin{itemize}
	\item \textbf{Chapter 2: Estado del arte} \\
	Basic concepts related to electrocardiograms are presented, highlighting the importance of their waves (P, QRS, T) and the most common anomalies typically detected. Furthermore, the literature related to the use of neural networks in the analysis of ECG's is reviewed, and relevant databases (such as PTB-XL) are described.
	
	\item  \textbf{Chapter 3: Metodología y preparación de datos} \\
	The process for handling ECG's is detailed, including the division into training, validation, and test sets. In addition, the metrics used to evaluate the models and the transformations employed are described.
	
	\item \textbf{Chapter 4: Entrenamiento y resultados}\\
	The training conditions for each model (including modifications to the original model) and the libraries used are explained, and the quantitative results obtained through the metrics are presented and compared.
	
	\item \textbf{Chapter 5: Explicabilidad}\\
	The gradient-based \emph{saliency maps} explainability method applied to Ribeiro’s model is described. In addition, the perspective of a specialist physician analyzing the generated explanations is included, and reflections on the method and potential improvements are discussed.
	
	\item \textbf{Chapter 6: Conclusiones y trabajo futuro}\\
	The conclusions derived from the results are integrated, assessing the extent to which the stated objectives have been met. Furthermore, the main contributions of this work are identified, and future research directions are proposed (such as the inclusion of Conv2D layers).
\end{itemize}

Finally, a bibliography section is included, containing all the sources consulted throughout the document, as well as an appendix with the code used\footnote{All the content of this work can be found in \href{https://github.com/NotNoe/TFG-Info}{this GitHub repository}.} and another with the physician’s comments transcribed.


